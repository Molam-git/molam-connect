name: Playground Observability & Metrics

on:
  push:
    branches: [main, develop]
    paths:
      - 'brique-118/src/**'
      - 'brique-118/tests/jest/trace.test.ts'
      - '.github/workflows/playground-metrics.yml'
  pull_request:
    branches: [main, develop]
  workflow_dispatch:

jobs:
  # Job 1: Metrics Tests
  metrics-tests:
    name: Metrics & Traces Tests
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: 'brique-118/tests/jest/package-lock.json'

      - name: Install dependencies
        working-directory: brique-118/tests/jest
        run: npm ci

      - name: Run metrics tests
        working-directory: brique-118/tests/jest
        env:
          DEV_TOKEN: test-dev-token-12345
          OPS_TOKEN: test-ops-token-67890
        run: npm run test:metrics

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: metrics-test-results
          path: brique-118/tests/jest/coverage

  # Job 2: Prometheus Integration Test
  prometheus-integration:
    name: Prometheus Integration
    runs-on: ubuntu-latest
    needs: metrics-tests

    services:
      prometheus:
        image: prom/prometheus:latest
        ports:
          - 9090:9090
        volumes:
          - ${{ github.workspace }}/brique-118/deploy/prometheus.yml:/etc/prometheus/prometheus.yml
        options: >-
          --health-cmd "wget -q --spider http://localhost:9090/-/healthy || exit 1"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Install dependencies
        working-directory: brique-118
        run: |
          cd tests/jest
          npm ci

      - name: Start metrics server
        working-directory: brique-118
        run: |
          cd tests/jest
          node -r ts-node/register ../../src/server.ts &
          SERVER_PID=$!
          echo "SERVER_PID=$SERVER_PID" >> $GITHUB_ENV
          sleep 5

      - name: Verify metrics endpoint
        run: |
          curl -f http://localhost:3000/metrics || exit 1
          echo "‚úÖ Metrics endpoint responding"

      - name: Generate test metrics
        run: |
          # Generate some test traffic
          for i in {1..10}; do
            curl -X POST http://localhost:3000/api/playground/run \
              -H "Content-Type: application/json" \
              -d '{"method":"GET","path":"/healthz"}' || true
            sleep 1
          done

      - name: Verify Prometheus scraping
        run: |
          # Wait for Prometheus to scrape
          sleep 20

          # Query Prometheus for our metrics
          curl -s 'http://localhost:9090/api/v1/query?query=molam_playground_test_runs_total' | grep -q "molam_playground_test_runs_total"
          echo "‚úÖ Prometheus is scraping metrics"

      - name: Stop metrics server
        if: always()
        run: |
          kill $SERVER_PID || true

  # Job 3: Grafana Dashboard Validation
  grafana-validation:
    name: Grafana Dashboard Validation
    runs-on: ubuntu-latest
    needs: prometheus-integration

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Validate dashboard JSON
        run: |
          if [ -f "brique-118/deploy/grafana-dashboard.json" ]; then
            cat brique-118/deploy/grafana-dashboard.json | jq . > /dev/null
            echo "‚úÖ Grafana dashboard JSON is valid"
          else
            echo "‚ÑπÔ∏è  No Grafana dashboard found (optional)"
          fi

  # Job 4: Performance Benchmarks
  performance-benchmarks:
    name: Metrics Performance Benchmarks
    runs-on: ubuntu-latest
    needs: metrics-tests

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Install dependencies
        working-directory: brique-118/tests/jest
        run: npm ci

      - name: Run performance benchmarks
        working-directory: brique-118
        run: |
          node -r ts-node/register -e "
          const { recordTestRun, recordFuzzingAlert } = require('./src/metrics');

          console.log('Running performance benchmarks...');

          // Benchmark 1: Metric recording speed
          const start1 = Date.now();
          for (let i = 0; i < 10000; i++) {
            recordTestRun('success', 'GET', '/healthz');
          }
          const duration1 = Date.now() - start1;
          console.log(\`‚úÖ 10,000 metric updates: \${duration1}ms\`);

          if (duration1 > 1000) {
            console.error('‚ùå Performance regression detected!');
            process.exit(1);
          }

          // Benchmark 2: Metrics export speed
          const { register } = require('./src/metrics');
          const start2 = Date.now();
          const metrics = register.metrics();
          const duration2 = Date.now() - start2;
          console.log(\`‚úÖ Metrics export: \${duration2}ms\`);

          if (duration2 > 100) {
            console.error('‚ùå Export too slow!');
            process.exit(1);
          }

          console.log('‚úÖ All performance benchmarks passed');
          "

      - name: Generate benchmark report
        run: |
          echo "# Performance Benchmarks" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "‚úÖ Metric recording: < 1000ms for 10k updates" >> $GITHUB_STEP_SUMMARY
          echo "‚úÖ Metrics export: < 100ms" >> $GITHUB_STEP_SUMMARY

  # Job 5: Summary
  metrics-summary:
    name: Metrics Test Summary
    runs-on: ubuntu-latest
    needs: [metrics-tests, prometheus-integration, grafana-validation, performance-benchmarks]
    if: always()

    steps:
      - name: Generate summary
        run: |
          echo "# üìä Playground Observability & Metrics Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Component | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|-----------|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| Metrics Tests | ${{ needs.metrics-tests.result == 'success' && '‚úÖ Passed' || '‚ùå Failed' }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Prometheus Integration | ${{ needs.prometheus-integration.result == 'success' && '‚úÖ Passed' || '‚ùå Failed' }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Grafana Validation | ${{ needs.grafana-validation.result == 'success' && '‚úÖ Passed' || '‚ùå Failed' }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Performance Benchmarks | ${{ needs.performance-benchmarks.result == 'success' && '‚úÖ Passed' || '‚ùå Failed' }} |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Metrics Exported" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "‚úÖ molam_playground_test_runs_total" >> $GITHUB_STEP_SUMMARY
          echo "‚úÖ molam_playground_fuzzing_alerts_total" >> $GITHUB_STEP_SUMMARY
          echo "‚úÖ molam_playground_rate_limit_hits_total" >> $GITHUB_STEP_SUMMARY
          echo "‚úÖ molam_playground_rbac_violations_total" >> $GITHUB_STEP_SUMMARY
          echo "‚úÖ molam_playground_request_duration_seconds" >> $GITHUB_STEP_SUMMARY
          echo "‚úÖ molam_playground_payload_size_bytes" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "üéØ All observability tests completed!" >> $GITHUB_STEP_SUMMARY
