# Brique 113: SIRA Inference Service - Environment Variables

# ============================================================================
# Server Configuration
# ============================================================================

NODE_ENV=development
PORT=8080
HOST=0.0.0.0
LOG_LEVEL=info

# ============================================================================
# Database
# ============================================================================

DATABASE_URL=postgresql://postgres:postgres@localhost:5432/molam
DB_POOL_MIN=2
DB_POOL_MAX=10

# ============================================================================
# Authentication
# ============================================================================

# JWT Secret for Molam ID tokens
JWT_SECRET=molam-jwt-secret-change-me-in-production

# Internal service-to-service token
INTERNAL_SERVICE_TOKEN=internal-service-token-change-me

# ============================================================================
# AWS / S3
# ============================================================================

AWS_REGION=us-east-1
AWS_ACCESS_KEY_ID=your-access-key-id
AWS_SECRET_ACCESS_KEY=your-secret-access-key
MODEL_BUCKET=molam-models

# ============================================================================
# Model Configuration
# ============================================================================

# Local directory for model storage
MODELS_DIR=/tmp/models

# Model check interval (ms)
MODEL_CHECK_INTERVAL_MS=30000

# ============================================================================
# Cache Configuration
# ============================================================================

# LRU Cache max items
CACHE_MAX_ITEMS=5000

# Cache TTL in milliseconds (5 minutes)
CACHE_TTL_MS=300000

# ============================================================================
# Inference Configuration
# ============================================================================

# Default threshold for decision-making
DEFAULT_THRESHOLD=0.5

# ============================================================================
# Service Metadata
# ============================================================================

SERVICE_VERSION=1.0.0
POD_ID=local

# ============================================================================
# Optional: Redis (for distributed cache)
# ============================================================================

# REDIS_URL=redis://localhost:6379

# ============================================================================
# Optional: Observability
# ============================================================================

# OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4318
# OTEL_SERVICE_NAME=sira-inference
