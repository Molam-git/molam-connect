# Brique 59 - SIRA: Dispute Analytics & Auto-Resolution

**SIRA** (Self-Improving Resolution Analytics) is Molam Connect's machine learning-powered dispute analytics and auto-resolution engine. It analyzes past disputes, generates merchant and sector profiles, provides predictive scoring, and continuously improves itself through automated patching and retraining.

## Key Features

- **ML-Powered Dispute Scoring**: Predict dispute win probability with confidence scores
- **Merchant Profiling**: Automated analysis of merchant dispute patterns and performance
- **Sector Benchmarking**: Compare merchants against sector averages with percentile rankings
- **Self-Improvement**: Automated patch testing, evaluation, and deployment
- **Dynamic Widgets**: Context-aware UI recommendations based on merchant performance
- **Feedback Loop**: Continuous learning from actual dispute outcomes
- **Model Versioning**: A/B testing and rollback capabilities
- **Auto-Resolution**: Achieve >60% automation with high-confidence predictions

---

## Architecture

### ML Model Pipeline

```
┌─────────────────────┐
│  Dispute Created    │
└──────┬──────────────┘
       │
       ▼
┌─────────────────────┐
│ Feature Extraction  │
│ - Amount, currency  │
│ - Reason code       │
│ - Evidence count    │
│ - Merchant profile  │
│ - Sector benchmarks │
└──────┬──────────────┘
       │
       ▼
┌─────────────────────┐
│  SIRA ML API        │
│  Predict win prob   │
└──────┬──────────────┘
       │
       ▼
┌─────────────────────┐
│ Benchmark Adjust    │
│ Merchant vs Sector  │
└──────┬──────────────┘
       │
       ▼
┌─────────────────────┐
│ Recommended Action  │
│ - auto_submit (90%+)│
│ - suggest_submit    │
│ - suggest_refund    │
│ - manual_review     │
└─────────────────────┘
```

### Self-Improvement Loop

```
┌──────────────────────────────────────────────┐
│              Feedback Loop                   │
│                                              │
│  Prediction → Outcome → Accuracy Check       │
│       ↓           ↓            ↓             │
│   Store      Record      Update Model        │
│                                              │
└────────────┬─────────────────────────────────┘
             │
             ▼
      ┌─────────────┐
      │ Retrainer   │ (Daily)
      │ Check < 65% │
      │ accuracy    │
      └──────┬──────┘
             │
             ▼
      ┌─────────────┐
      │ ML API      │
      │ Retrain     │
      │ New Version │
      └──────┬──────┘
             │
             ▼
      ┌─────────────┐
      │ Test in     │
      │ Sandbox     │
      └──────┬──────┘
             │
             ▼
      ┌─────────────┐
      │ Auto-Deploy │
      │ if > 5% ↑   │
      └─────────────┘
```

---

## Database Schema

### Core Tables

**merchant_dispute_profiles**
- Aggregated merchant dispute statistics
- Win rate, resolution time, evidence quality
- Sector benchmarks for comparison

**sector_benchmarks**
- Percentile rankings (P25, P50, P75) by sector/country/currency
- Updated hourly via analyticsWorker

**sira_models**
- ML model versioning (active/testing/archived)
- Training metadata, hyperparameters, feature importance
- Accuracy tracking

**sira_predictions**
- All predictions with features used
- Links to dispute outcomes for feedback loop
- Prediction correctness tracking

**sira_patches**
- Self-improvement patches (code/hyperparameters/data)
- Sandbox test results with accuracy delta
- Deployment status and approval workflow

**sira_recommendations**
- AI-generated recommendations per merchant
- Priority-based (1-3), dismissible
- Automatically generated by analyticsWorker

---

## API Reference

### Scoring & Predictions

#### `POST /api/sira/score-dispute`
Score a dispute with ML model.

**Request:**
```json
{
  "id": "dispute-uuid",
  "amount": 125.00,
  "currency": "USD",
  "reason_code": "13.1",
  "country": "US",
  "merchant_id": "merchant-uuid",
  "created_at": "2025-01-10T12:00:00Z"
}
```

**Response:**
```json
{
  "win_probability": 0.78,
  "confidence": 0.82,
  "recommended_action": "suggest_submit",
  "reasons": [
    "Strong evidence package detected",
    "Merchant win rate above sector average"
  ],
  "model_version": "v2.3.1",
  "prediction_time_ms": 145
}
```

#### `POST /api/sira/outcome`
Record actual dispute outcome for feedback loop.

**Request:**
```json
{
  "dispute_id": "dispute-uuid",
  "outcome": "won"
}
```

**Response:**
```json
{
  "ok": true
}
```

### Merchant Analytics

#### `GET /api/sira/profiles/:merchantId`
Get merchant dispute profile.

**Response:**
```json
{
  "merchant_id": "merchant-uuid",
  "sector": "retail",
  "country": "US",
  "total_disputes": 1247,
  "win_rate": 68.5,
  "loss_rate": 22.3,
  "settled_rate": 9.2,
  "avg_resolution_days": 42,
  "evidence_quality_score": 0.82,
  "sira_accuracy": 0.75,
  "benchmark_win_rate": 62.0,
  "benchmark_resolution_days": 45,
  "updated_at": "2025-01-10T08:00:00Z"
}
```

#### `GET /api/sira/benchmarks/:sector/:country`
Get sector benchmarks.

**Query Params:**
- `currency` (optional): Filter by currency
- `reason_code` (optional): Filter by reason code

**Response:**
```json
{
  "sector": "retail",
  "country": "US",
  "currency": "USD",
  "dispute_count": 45230,
  "win_rate_p25": 55.0,
  "win_rate_p50": 62.0,
  "win_rate_p75": 72.0,
  "resolution_days_p25": 35,
  "resolution_days_p50": 45,
  "resolution_days_p75": 58
}
```

### Dynamic Widgets

#### `GET /api/sira/widgets`
Get dynamic widget recommendations for merchant.

**Response:**
```json
{
  "widgets": [
    {
      "type": "recommendation",
      "priority": "high",
      "title": "Win Rate Below Sector Average",
      "text": "Your win rate (58.2%) is below the retail sector average (62.0%). Consider improving evidence quality.",
      "action": {
        "label": "View Evidence Tips",
        "link": "/evidence-builder"
      }
    },
    {
      "type": "insight",
      "priority": "low",
      "title": "Strong SIRA Performance",
      "text": "SIRA predictions are 82% accurate for your disputes.",
      "action": {
        "label": "Enable Auto-Submit",
        "link": "/settings/sira"
      }
    }
  ]
}
```

### Model Management (Admin)

#### `GET /api/sira/models`
List all ML models.

#### `POST /api/sira/models/:id/activate`
Activate a specific model version.

#### `GET /api/sira/predictions?has_outcome=true`
List predictions with actual outcomes.

### Self-Improvement (Admin)

#### `POST /api/sira/patches`
Propose a new self-improvement patch.

**Request:**
```json
{
  "patch_name": "improve_fraud_feature",
  "model_version": "v2.3.1",
  "patch_type": "feature_engineering",
  "code_diff": "diff --git a/features.py ...",
  "description": "Add fraud score as feature"
}
```

#### `POST /api/sira/patches/:id/test`
Test patch in sandbox environment.

**Response:**
```json
{
  "passed": true,
  "accuracyBefore": 0.745,
  "accuracyAfter": 0.782,
  "improvement": 0.037
}
```

#### `POST /api/sira/patches/:id/deploy`
Deploy approved patch to production.

---

## Self-Improvement Workflow

SIRA can modify its own code through a rigorous patch testing workflow:

### 1. Patch Proposal
- Ops team or automated system proposes patch
- Types: `code`, `hyperparameters`, `training_data`, `feature_engineering`
- Includes git-style diff for code changes

### 2. Sandbox Testing
```typescript
// Automatically clones repo, applies patch, runs tests
const result = await testPatch(patchId);
// Measures accuracy on validation set before/after
```

### 3. Accuracy Evaluation
- Compare accuracy delta: `accuracyAfter - accuracyBefore`
- Store test results in database
- Mark patch as `testing` status

### 4. Auto-Deployment Decision
```typescript
const AUTO_DEPLOY_THRESHOLD = 0.05; // 5% improvement

if (patch.accuracy_improvement >= AUTO_DEPLOY_THRESHOLD) {
  await deployPatch(patchId, 'auto_deployer');
  // Creates PR in main repo
  // Triggers CI/CD pipeline
}
```

### 5. Human Approval (Optional)
- If improvement < threshold, requires `pay_admin` approval
- Admin reviews test results and approves deployment
- Audit trail maintained in `molam_audit_logs`

---

## Feature Engineering

SIRA extracts the following features from disputes:

### Transaction Features
- `amount`: Dispute amount (normalized)
- `currency`: Currency code
- `reason_code`: Card network reason code
- `country`: Merchant country
- `age_days`: Days since dispute created

### Merchant Features
- `merchant_id`: Merchant identifier
- `evidence_count`: Number of evidence files submitted
- `evidence_quality_score`: Quality assessment (0-1)
- `merchant_win_rate`: Historical win rate %
- `sector_avg_win_rate`: Sector benchmark %

### Dynamic Features
- `merchantVsSector`: `merchant_win_rate - sector_avg_win_rate`
- `evidence_timing`: Days between creation and submission
- `network_deadline_urgency`: Days until network deadline

---

## Workers

### analyticsWorker (Hourly)
```bash
npm run worker:analytics
```

**Responsibilities:**
1. Rebuild merchant profiles for all merchants with recent disputes
2. Recalculate sector benchmarks (P25, P50, P75)
3. Generate AI recommendations for underperforming merchants
4. Update `merchant_dispute_profiles` and `sector_benchmarks` tables

### modelRetrainer (Daily)
```bash
npm run worker:retrainer
```

**Responsibilities:**
1. Evaluate active model accuracy on recent predictions
2. Trigger retraining if accuracy drops below 65%
3. Create new model version with updated training data
4. Auto-test patches and deploy if improvement >= 5%
5. Monitor feature drift and update `sira_feature_importance`

---

## Recommended Actions

SIRA provides context-aware recommendations based on probability and confidence:

| Win Probability | Confidence | Action |
|----------------|-----------|---------|
| > 90% | > 85% | **auto_submit** - Automatically submit to network |
| > 70% | Any | **suggest_submit** - Recommend submission |
| < 30% | Any | **suggest_refund** - Recommend proactive refund |
| 30-70% | Any | **manual_review** - Require human review |

---

## Benchmark Methodology

### Sector Aggregation

Benchmarks are calculated per `(sector, country, currency, reason_code)` combination:

```sql
SELECT
  sector,
  country,
  currency,
  PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY win_rate) AS win_rate_p25,
  PERCENTILE_CONT(0.50) WITHIN GROUP (ORDER BY win_rate) AS win_rate_p50,
  PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY win_rate) AS win_rate_p75
FROM merchant_dispute_profiles
WHERE updated_at > NOW() - INTERVAL '90 days'
GROUP BY sector, country, currency;
```

### Benchmark Adjustment

Raw ML predictions are adjusted based on merchant performance vs sector:

```typescript
const merchantVsSector = merchant_win_rate - sector_avg_win_rate;
let adjustment = 0;

if (merchantVsSector > 10) {
  adjustment = 0.05; // Boost probability by 5%
} else if (merchantVsSector < -10) {
  adjustment = -0.05; // Lower probability by 5%
}

const adjusted = Math.max(0, Math.min(1, rawProbability + adjustment));
```

---

## Deployment

### Environment Variables

```bash
# Database
DATABASE_URL=postgresql://user:pass@localhost:5432/molam

# ML API
SIRA_ML_API_URL=http://localhost:9000

# Auto-Deployment
ENABLE_AUTO_PATCHES=true
AUTO_DEPLOY_THRESHOLD=0.05

# Sandbox
SANDBOX_REPO_PATH=/tmp/sira-sandbox
SIRA_REPO_URL=git@github.com:molam/sira.git

# Server
PORT=8059
```

### Installation

```bash
cd brique-59
npm install
```

### Run Migration

```bash
psql $DATABASE_URL -f migrations/059_sira_analytics.sql
```

### Start Services

```bash
# API Server
npm run start

# Analytics Worker (hourly)
npm run worker:analytics

# Model Retrainer (daily)
npm run worker:retrainer
```

### Build

```bash
npm run build
```

---

## Monitoring

### Prometheus Metrics

Available at `http://localhost:8059/metrics`:

- `sira_predictions_total` - Total predictions made
- `sira_predictions_correct` - Correct predictions
- `sira_model_accuracy` - Current model accuracy
- `sira_patch_deployments_total` - Auto-deployed patches
- `sira_api_latency_ms` - Prediction latency

### Health Check

```bash
curl http://localhost:8059/health
```

**Response:**
```json
{
  "status": "healthy",
  "service": "sira-analytics"
}
```

---

## React Components

### SiraWidgets
Dynamic widget container for merchant dashboard.

```tsx
import SiraWidgets from './SiraWidgets';

<SiraWidgets merchantId="merchant-uuid" />
```

### BenchmarkCard
Merchant vs sector performance comparison.

```tsx
import BenchmarkCard from './BenchmarkCard';

<BenchmarkCard merchantId="merchant-uuid" />
```

### RecommendationCard
AI-generated recommendations for merchants.

```tsx
import RecommendationCard from './RecommendationCard';

<RecommendationCard merchantId="merchant-uuid" />
```

### ModelPerformance (Admin)
Model accuracy dashboard for ops team.

```tsx
import ModelPerformance from './ModelPerformance';

<ModelPerformance />
```

---

## Security

### Authorization

All endpoints require JWT authentication:

```typescript
headers: {
  Authorization: `Bearer ${token}`
}
```

### RBAC Permissions

- **merchant_admin**: View own profile, recommendations, widgets
- **pay_admin**: View all profiles, manage models, deploy patches
- **finance_ops**: Score disputes, record outcomes

### Audit Trail

All model changes, patch deployments, and accuracy evaluations are logged to `molam_audit_logs`:

```sql
SELECT * FROM molam_audit_logs
WHERE entity_type = 'sira_model'
ORDER BY created_at DESC;
```

---

## Performance Targets

- **Prediction Latency**: < 200ms (p95)
- **Auto-Resolution Rate**: > 60%
- **Model Accuracy**: > 70% (on historical data)
- **Benchmark Update Frequency**: Hourly
- **Profile Update Frequency**: Hourly
- **Model Retraining**: Daily (if needed)

---

## Troubleshooting

### Low Model Accuracy

1. Check recent predictions:
   ```sql
   SELECT COUNT(*) FILTER (WHERE prediction_correct = true) as correct,
          COUNT(*) as total
   FROM sira_predictions
   WHERE created_at > NOW() - INTERVAL '7 days';
   ```

2. Trigger manual retraining:
   ```bash
   curl -X POST http://localhost:8059/api/sira/models/retrain \
     -H "Authorization: Bearer $TOKEN"
   ```

### Missing Benchmarks

1. Force rebuild:
   ```bash
   curl -X POST http://localhost:8059/api/sira/benchmarks/rebuild \
     -H "Content-Type: application/json" \
     -d '{"sector": "retail", "country": "US", "currency": "USD"}'
   ```

### Patch Test Failures

1. Check sandbox logs:
   ```bash
   tail -f /tmp/sira-sandbox/test.log
   ```

2. Review patch status:
   ```sql
   SELECT * FROM sira_patches WHERE status = 'rejected';
   ```

---

## Future Enhancements

- [ ] Multi-model ensembling (combine multiple model predictions)
- [ ] Real-time feature drift detection with alerts
- [ ] Explainable AI (SHAP values for predictions)
- [ ] Automated A/B testing for new models
- [ ] Merchant-specific model fine-tuning
- [ ] Integration with external fraud signals (Device fingerprinting, IP reputation)

---

## License

Proprietary - Molam Connect 2025
